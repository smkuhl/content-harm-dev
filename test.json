{
    "gptBlock": {
        "text": {
            "text": "ProMISe introduces an *iterative SQA system* to aid information-seeking, generating 17812 SQAs across 1025 dialogues. It's linked to <https://scholar-assistant.public.apps.allenai.org/paper/db68cc363587bf82acf5a373b68bbf8a6bc11ac9?channel=C0431S1CZFG&team=T0EJFTLJG&source=h5C|Speak Out of Turn: Safety...> _(:thread: in prev thread)_ as both explore multi-turn dialogues with LLMs. Xinyi suggests fixing link formats, hinting at the importance of post-processing in enhancing dialogue safety and user satisfaction in related research.",
            "type": "mrkdwn",
            "verbatim": false
        },
        "type": "section",
        "accessory": {
            "url": "https://uw-cse.slack.com/archives/C0431S1CZFG/p1709935400894589",
            "text": {
                "text": ":thread: view prev thread",
                "type": "plain_text",
                "emoji": true
            },
            "type": "button",
            "value": "{\"action\":\"thread-link-action\",\"condition\":\"h5C\",\"url\":\"https://uw-cse.slack.com/archives/C0431S1CZFG/p1709935400894589\"}",
            "action_id": "thread-link-action"
        }
    },
    "condition": 3,
    "gptMessage": {
        "prompt3": "\n  You are a helpful assistant for paper summarization.\n\n  The paper has the following details:\n  * Abstract: {Users of AI-based virtual assistants and search systems encounter challenges in articulating their intents while seeking information on unfamiliar topics, possibly due to complexity of the user’s intent or the lack of meta-information on the topic. We posit that an iterative suggested question-answering (SQA) conversation can improve the trade-off between the satisfaction of the user’s intent while keeping the information exchange natural and cognitive load of the interaction minimal on the users. In this paper, we evaluate a novel setting ProMISe by means of a sequence of interactions between a user, having a predefined information-seeking intent, and an agent that generates a set of SQA pairs at each step to aid the user to get closer to their intent. We simulate this two-player setting to create a multi-turn conversational dataset of SQAs and user choices (1025 dialogues comprising 4453 turns and 17812 SQAs) using human-feedback, chain-of-thought prompting and web-retrieval augmented large language models. We evaluate the quality of the SQs in the dataset on attributes such as diversity, specificity, grounding, etc, and benchmark the performance of different language models for the task of replicating user behavior.}\n  * Authors: Y. Butala, Siddhant Garg, Pratyay Banerjee, Amita Misra\n\n  In your summarization, you must\n  * Keep your output less than 300 characters.\n  * Be informative.\n  * If applicable, be specific about the numbers in the abstract that may refer to the proposed method's performance.\n  ",
        "prompt4": "\n  You are a helpful assistant.\n\n  Title: ProMISe: A Proactive Multi-turn Dialogue Dataset for Information-seeking Intent Resolution\n  Abstract: {Users of AI-based virtual assistants and search systems encounter challenges in articulating their intents while seeking information on unfamiliar topics, possibly due to complexity of the user’s intent or the lack of meta-information on the topic. We posit that an iterative suggested question-answering (SQA) conversation can improve the trade-off between the satisfaction of the user’s intent while keeping the information exchange natural and cognitive load of the interaction minimal on the users. In this paper, we evaluate a novel setting ProMISe by means of a sequence of interactions between a user, having a predefined information-seeking intent, and an agent that generates a set of SQA pairs at each step to aid the user to get closer to their intent. We simulate this two-player setting to create a multi-turn conversational dataset of SQAs and user choices (1025 dialogues comprising 4453 turns and 17812 SQAs) using human-feedback, chain-of-thought prompting and web-retrieval augmented large language models. We evaluate the quality of the SQs in the dataset on attributes such as diversity, specificity, grounding, etc, and benchmark the performance of different language models for the task of replicating user behavior.}\n\n  Title: Speak Out of Turn: Safety Vulnerability of Large Language Models in Multi-turn Dialogue\n  Abstract: {Large Language Models (LLMs) have been demonstrated to generate illegal or unethical responses, particularly when subjected to\"jailbreak.\"Research on jailbreak has highlighted the safety issues of LLMs. However, prior studies have predominantly focused on single-turn dialogue, ignoring the potential complexities and risks presented by multi-turn dialogue, a crucial mode through which humans derive information from LLMs. In this paper, we argue that humans could exploit multi-turn dialogue to induce LLMs into generating harmful information. LLMs may not intend to reject cautionary or borderline unsafe queries, even if each turn is closely served for one malicious purpose in a multi-turn dialogue. Therefore, by decomposing an unsafe query into several sub-queries for multi-turn dialogue, we induced LLMs to answer harmful sub-questions incrementally, culminating in an overall harmful response. Our experiments, conducted across a wide range of LLMs, indicate current inadequacies in the safety mechanisms of LLMs in multi-turn dialogue. Our findings expose vulnerabilities of LLMs in complex scenarios involving multi-turn dialogue, presenting new challenges for the safety of LLMs.}\n\n  The first paragraph of your answer should explain and specify the relationship between ProMISe: A Proactive Multi-turn Dialogue Dataset for Information-seeking Intent Resolution and Speak Out of Turn: Safety Vulnerability of Large Language Models in Multi-turn Dialogue. Be informative.\n  * In this first paragraph of your answer, you must explain and specify how ProMISe: A Proactive Multi-turn Dialogue Dataset for Information-seeking Intent Resolution is related to Speak Out of Turn: Safety Vulnerability of Large Language Models in Multi-turn Dialogue in one short sentence.\n  * In this first paragraph of your answer, you must start with \"This paper might be related to Speak Out of Turn: Safety Vulnerability of Large Language Models in Multi-turn Dialogue because\".\n  * The first paragraph should have no more than 400 characters.\n\n  People's comments about Speak Out of Turn: Safety Vulnerability of Large Language Models in Multi-turn Dialogue: {Xinyi: To fix:\n• Link format. Should address post-processing}\n\n  The second paragraph of your answer should specify what people think about Speak Out of Turn: Safety Vulnerability of Large Language Models in Multi-turn Dialogue and who these people are. Be informative.\n  * In this second paragraph of your answer, you must start with \"Comments about Speak Out of Turn: Safety Vulnerability of Large Language Models in Multi-turn Dialogue\". Note that user A 'cc' user B means that A thought Speak Out of Turn: Safety Vulnerability of Large Language Models in Multi-turn Dialogue is related to B's research, projects, or interests. Comments would not be negative.\n  * In this second paragraph of your answer, you must NOT add in-line citations and citation numbers.\n  * The second paragraph should have no more than 200 characters.\n\n  Your answer should replace ProMISe: A Proactive Multi-turn Dialogue Dataset for Information-seeking Intent Resolution with \"this paper\".",
        "buttonUrl": "https://uw-cse.slack.com/archives/C0431S1CZFG/p1709935400894589",
        "prompt345": " \n    You are a helpful assistant for paper summarization.\n\n    {Study introduces ProMISe, an iterative SQA system to aid info-seeking. It uses human feedback and AI to generate 17812 SQAs across 1025 dialogues, improving user intent satisfaction with minimal cognitive load.  This paper might be related to Speak Out of Turn: Safety Vulnerability of Large Language Models in Multi-turn Dialogue because both explore multi-turn dialogues with LLMs. Comments about Speak Out of Turn: Safety Vulnerability of Large Language Models in Multi-turn Dialogue include Xinyi's suggestion to fix the link format for post-processing.}\n    \n    First, you are required to shorten the above content with no more than 371 characters. Note that:\n    - The shortened content must contain the following strings: Speak Out of Turn: Safety Vulnerability of Large Language Models in Multi-turn Dialogue\n    - Two papers are mentioned in {This paper might be related to Speak Out of Turn: Safety Vulnerability of Large Language Models in Multi-turn Dialogue because both explore multi-turn dialogues with LLMs. Comments about Speak Out of Turn: Safety Vulnerability of Large Language Models in Multi-turn Dialogue include Xinyi's suggestion to fix the link format for post-processing.}. When you specify people's  or comments about Speak Out of Turn: Safety Vulnerability of Large Language Models in Multi-turn Dialogue, you should focus more on who  or commented and how these  or comments infer the potential  or comments about another paper based on the two papers' similarities than people's  or comments about Speak Out of Turn: Safety Vulnerability of Large Language Models in Multi-turn Dialogue.\n    - Do not remove any person's name (with or without '@'), institution's name, number, and conference/journal's name.\n    - Do not change the content's tone when it is low-confidence.\n    \n    Second, you are required to bold at most three key phrases of the shortened content by adding ONE '*' to the left of the bolded text and ONE '*' to the right of the bolded text.\n    You should only bold the following text:\n    - The text tells what a paper is about.\n    - The text explains why a paper might be related to another paper or why a user might be interested in a paper, which is often after (does not include) the keywords such as \"because\" and \"due to\".\n    You should not bold the following text:\n    - Speak Out of Turn: Safety Vulnerability of Large Language Models in Multi-turn Dialogue\n    ",
        "final_output": "ProMISe introduces an *iterative SQA system* to aid information-seeking, generating 17812 SQAs across 1025 dialogues. It's linked to <https://scholar-assistant.public.apps.allenai.org/paper/db68cc363587bf82acf5a373b68bbf8a6bc11ac9?channel=C0431S1CZFG&team=T0EJFTLJG&source=h5C|Speak Out of Turn: Safety...> _(:thread: in prev thread)_ as both explore multi-turn dialogues with LLMs. Xinyi suggests fixing link formats, hinting at the importance of post-processing in enhancing dialogue safety and user satisfaction in related research.",
        "prompt3Output": "Study introduces ProMISe, an iterative SQA system to aid info-seeking. It uses human feedback and AI to generate 17812 SQAs across 1025 dialogues, improving user intent satisfaction with minimal cognitive load.",
        "prompt4Output": "This paper might be related to Speak Out of Turn: Safety Vulnerability of Large Language Models in Multi-turn Dialogue because both explore multi-turn dialogues with LLMs. Comments about Speak Out of Turn: Safety Vulnerability of Large Language Models in Multi-turn Dialogue include Xinyi's suggestion to fix the link format for post-processing.",
        "final_output_noLink": "ProMISe introduces an *iterative SQA system* to aid information-seeking, generating 17812 SQAs across 1025 dialogues. It's linked to Speak Out of Turn: Safety... as both explore multi-turn dialogues with LLMs. Xinyi suggests fixing link formats, hinting at the importance of post-processing in enhancing dialogue safety and user satisfaction in related research.",
        "finalPickedCondition": "4",
        "finalPickedConditionLetter": "h5C"
    },
    "connectionBlock": [
        {
            "text": {
                "text": ":link: Related paper: <https://scholar-assistant.public.apps.allenai.org/paper/db68cc363587bf82acf5a373b68bbf8a6bc11ac9?channel=C0431S1CZFG&team=T0EJFTLJG&source=h5C|Speak Out of Turn: Safety Vulnerability of Large...> (:thread: in prev thread which received 1 replies)",
                "type": "mrkdwn"
            },
            "type": "section",
            "accessory": {
                "url": "https://uw-cse.slack.com/archives/C0431S1CZFG/p1709935400894589",
                "text": {
                    "text": ":thread: view prev thread",
                    "type": "plain_text",
                    "emoji": true
                },
                "type": "button",
                "value": "{\"action\":\"thread-link-action\",\"condition\":\"h5C_template\",\"url\":\"https://uw-cse.slack.com/archives/C0431S1CZFG/p1709935400894589\"}",
                "action_id": "thread-link-action"
            }
        }
    ],
    "paperDetailsBlock": {
        "text": {
            "text": "*<https://scholar-assistant.public.apps.allenai.org/paper/d41d97617a20427fda4fd899a3004793f981de74?channel=C0431S1CZFG&source=h0&team=T0EJFTLJG&utm_content=title&utm_medium=alert&utm_source=slackbot|ProMISe: A Proactive Multi-turn Dialogue Dataset for Information-seeking Intent Resolution>*\n<https://scholar-assistant.public.apps.allenai.org/author/2287828804?channel=C0431S1CZFG&source=h0&team=T0EJFTLJG&utm_content=author&utm_medium=alert&utm_source=slackbot|Y. Butala>, <https://scholar-assistant.public.apps.allenai.org/author/2291365152?channel=C0431S1CZFG&source=h0&team=T0EJFTLJG&utm_content=author&utm_medium=alert&utm_source=slackbot|Siddhant Garg>, <https://scholar-assistant.public.apps.allenai.org/author/2291366346?channel=C0431S1CZFG&source=h0&team=T0EJFTLJG&utm_content=author&utm_medium=alert&utm_source=slackbot|Pratyay Banerjee>, <https://scholar-assistant.public.apps.allenai.org/author/2291363690?channel=C0431S1CZFG&source=h0&team=T0EJFTLJG&utm_content=author&utm_medium=alert&utm_source=slackbot|Amita Misra>\nFindings |  2024 |  <https://www.semanticscholar.org/paper/d41d97617a20427fda4fd899a3004793f981de74/?channel=C0431S1CZFG&save_to_library=1&source=h0&team=T0EJFTLJG&utm_content=title&utm_medium=alert&utm_source=slackbot|:file_folder: Save to library>",
            "type": "mrkdwn"
        },
        "type": "section"
    },
    "tldrAbstractBlock": {
        "text": {
            "text": "TLDR: This paper evaluates a novel setting ProMISe by means of a sequence of interactions between a user, having a predefined information-seeking intent, and an agent that generates a set of SQA pairs at each step to aid the user to get closer to their intent.",
            "type": "mrkdwn"
        },
        "type": "section"
    }
}